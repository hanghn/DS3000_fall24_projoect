{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaa3c0a-e4d5-4d87-9ffc-57a8a87d7533",
   "metadata": {},
   "source": [
    "## Phase I Project Proposal\n",
    "### Evaluating the Impact of ESG Practices on Stock Valuations\n",
    "\n",
    "#### Name: Hang Hang, DS 3000 Mon, Wed 2:50p-4:30p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b35c0-18df-4b89-afc7-68b025e173dc",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The project will explore how Environmental, Social, and Governance (ESG) scores affect a company's stock performance. ESG scores are increasingly becoming a factor for investors when selecting companies, and this project aims to analyze if there is a clear link between strong ESG performance and financial outcomes in the market. By analyzing the relationship between a company's ESG rating and its stock price volatility or returns, I want to answer the below two key questions:\n",
    "\n",
    "- Do companies with higher ESG ratings experience lower stock price volatility?\n",
    "- Is there a correlation between ESG scores and stock returns over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c1309-aeda-4fb8-be0f-f034db67a826",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "To source real time data for analysis, I plan to use Yahoo Finance API which allows me to request stock prices, fundamental data (market cap, P/E ratio, etc.), and ESG metrics for thousands of tickers in an automated way. I will focus on numeric features (e.g., stock price, market cap, ESG risk scores) and categorical feature (ESG risk level, company sector, industries (the latter two I haven't scraped them yet)). Data will be filtered to include companies with a range of ESG scores, providing both high and low ESG focus cases for comparison. \n",
    "\n",
    "Please see below the approach I've had so far for extracting the data. To ensure sufficient sample size, I plan to pull the list of S&P 500 company (or it could be Fortune 1000 companies if we want more coverage) from Wikipedia as the list of tickers and pass them into my function (e.g. get_stock_data) for scraping data from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff284e6e-a5d7-4c33-969f-28bc033dd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69822ea-f347-4706-a16b-e33da41aa47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AMTM', 'AEE', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BAX', 'BDX', 'BRK.B', 'BBY', 'TECH', 'BIIB', 'BLK', 'BX', 'BK', 'BA', 'BKNG', 'BWA', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'BLDR', 'BG', 'BXP', 'CHRW', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CF', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CPAY', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CRWD', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DAY', 'DECK', 'DE', 'DELL', 'DAL', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ERIE', 'ESS', 'EL', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GE', 'GEHC', 'GEV', 'GEN', 'GNRC', 'GD', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GDDY', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'DOC', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KKR', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LLY', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PLTR', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SW', 'SNA', 'SOLV', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SMCI', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VTRS', 'VICI', 'V', 'VST', 'VMC', 'WRB', 'GWW', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WY', 'WMB', 'WTW', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of stock tickers for the S&P 500 companies from the Wikipedia page\n",
    "def get_sp500_symbols():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "\n",
    "    # Extract the tickers from the table\n",
    "    symbols = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        symbol = row.find('a').text\n",
    "        symbols.append(symbol)\n",
    "    return symbols\n",
    "\n",
    "symbols = get_sp500_symbols()\n",
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8157945f-0c9b-4cb0-b8e6-ec9af054cee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Market Cap (Intraday)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>5888.25</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker    Price Market Cap (Intraday)\n",
       "0    MMM  5888.25                   N/A\n",
       "1    AOS   5888.5                   N/A\n",
       "2    ABT   5888.5                   N/A\n",
       "3   ABBV   5888.5                   N/A\n",
       "4    ACN   5888.5                   N/A"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the stock price and market cap data\n",
    "def get_stock_data(tickers):\n",
    "    data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        url = f'https://finance.yahoo.com/quote/{ticker}'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract stock price and market cap\n",
    "        price = soup.find('fin-streamer', {'data-field': 'regularMarketPrice'})['data-value']\n",
    "        market_cap_tag = soup.find('fin-streamer', {'data-field': 'marketCap'})\n",
    "        market_cap = market_cap_tag.get('data-value', 'N/A') if market_cap_tag else 'N/A'\n",
    "        data.append({'Ticker': ticker, 'Price': price, 'Market Cap (Intraday)': market_cap})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "tickers = get_sp500_symbols()\n",
    "get_stock_data(tickers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25bd685-74e2-471b-90ef-30bd84816a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Total ESG</th>\n",
       "      <th>ESG Description</th>\n",
       "      <th>Environmental Risk</th>\n",
       "      <th>Social Risk</th>\n",
       "      <th>Governance Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Total ESG ESG Description Environmental Risk Social Risk  \\\n",
       "0    MMM       N/A             N/A                N/A         N/A   \n",
       "1    AOS       N/A             N/A                N/A         N/A   \n",
       "2    ABT       N/A             N/A                N/A         N/A   \n",
       "3   ABBV       N/A             N/A                N/A         N/A   \n",
       "4    ACN       N/A             N/A                N/A         N/A   \n",
       "\n",
       "  Governance Risk  \n",
       "0             N/A  \n",
       "1             N/A  \n",
       "2             N/A  \n",
       "3             N/A  \n",
       "4             N/A  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the ESG data\n",
    "def get_esg_scores(tickers):\n",
    "    esg_scores = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        url = f'https://finance.yahoo.com/quote/{ticker}/sustainability/'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Extract total ESG score and its description (percentile and risk level)\n",
    "        total_esg_section = soup.find('section', {'data-testid': 'TOTAL_ESG_SCORE'})\n",
    "\n",
    "        # Extract total ESG score and description\n",
    "        total_esg = total_esg_section.find('h4').text.strip() if total_esg_section else 'N/A'\n",
    "        esg_description = (total_esg_section.find_all('span')[-1].text.strip()\n",
    "                           if total_esg_section and total_esg_section.find_all('span') \n",
    "                           else 'N/A')\n",
    "            \n",
    "        # Extract environmental, social, and governance risk score\n",
    "        env_section = soup.find('section', {'data-testid': 'ENVIRONMENTAL_SCORE'})\n",
    "        env_risk = env_section.find('h4').text.strip() if env_section else 'N/A'\n",
    "\n",
    "        social_section = soup.find('section', {'data-testid': 'SOCIAL_SCORE'})\n",
    "        social_risk = social_section.find('h4').text.strip() if social_section else 'N/A'\n",
    "\n",
    "        gov_section = soup.find('section', {'data-testid': 'GOVERNANCE_SCORE'})\n",
    "        gov_risk = gov_section.find('h4').text.strip() if gov_section else 'N/A'\n",
    "        \n",
    "        esg_scores.append({\n",
    "                'Ticker': ticker,\n",
    "                'Total ESG': total_esg,\n",
    "                'ESG Description': esg_description,\n",
    "                'Environmental Risk': env_risk,\n",
    "                'Social Risk': social_risk,\n",
    "                'Governance Risk': gov_risk})\n",
    "\n",
    "    return pd.DataFrame(esg_scores)\n",
    "\n",
    "esg_df = get_esg_scores(tickers[:5])\n",
    "esg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84b20b5-7757-4057-91e8-791ecea6685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Market Cap (Intraday)</th>\n",
       "      <th>Total ESG</th>\n",
       "      <th>ESG Description</th>\n",
       "      <th>Environmental Risk</th>\n",
       "      <th>Social Risk</th>\n",
       "      <th>Governance Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>5888.5</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker   Price Market Cap (Intraday) Total ESG ESG Description  \\\n",
       "0    MMM  5888.5                   N/A       N/A             N/A   \n",
       "1    AOS  5888.5                   N/A       N/A             N/A   \n",
       "2    ABT  5888.5                   N/A       N/A             N/A   \n",
       "3   ABBV  5888.5                   N/A       N/A             N/A   \n",
       "4    ACN  5888.5                   N/A       N/A             N/A   \n",
       "\n",
       "  Environmental Risk Social Risk Governance Risk  \n",
       "0                N/A         N/A             N/A  \n",
       "1                N/A         N/A             N/A  \n",
       "2                N/A         N/A             N/A  \n",
       "3                N/A         N/A             N/A  \n",
       "4                N/A         N/A             N/A  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consolidate S&P500 tickers df and ESG scores df into a single df\n",
    "def consolidate_into_df(tickers):\n",
    "    stock_df = get_stock_data(tickers)\n",
    "    esg_df = get_esg_scores(tickers)\n",
    "\n",
    "    # Merge the two dataframes on the 'Ticker' column\n",
    "    consolidated_df = pd.merge(stock_df, esg_df, on='Ticker', how='left')\n",
    "    # Fill any missing values with 'N/A'\n",
    "    consolidated_df.fillna('N/A', inplace=True)\n",
    "    return consolidated_df\n",
    "    \n",
    "consolidated_df = consolidate_into_df(tickers[:5])\n",
    "consolidated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc86fe2-da01-4176-aa4d-58ab36838f8b",
   "metadata": {},
   "source": [
    "### Data Usage and Remaining Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af52bbe-04c5-4fc0-ace3-2035dba69416",
   "metadata": {},
   "source": [
    "The collected data will be used to conduct a comparative analysis between companies with high ESG ratings and those with low or no ESG focus. I am planning that after we get the chance to dive into machine learning models like regression and classification, I can predict stock price volatility based on ESG ratings and assess whether companies with higher ESG scores enjoy a valuation premium. The general approach will involve predicting numerical values (such as stock price) and characterizing relationships between ESG scores and financial metrics like stock price and market capitalization. The project will ultimately help determine whether ESG practices provide companies with a market advantage and if they can protect investors during turbulent times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
